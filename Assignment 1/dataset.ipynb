{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Topic Classification\n",
    "\n",
    "The project involves a large dataset of news articles collected over several years. These articles cover a wide range of topics such as world events, sports, business, and science/technology. Each article headline is labeled with a number from 0 to 3, indicating its category, as described below. \n",
    "\n",
    "| Value | Topic        |\n",
    "|:------|:-------------|\n",
    "| 0     | World        |\n",
    "| 1     | Sports       |\n",
    "| 2     | Business     |\n",
    "| 3     | Sci/Tech     |\n",
    "\n",
    "\n",
    "Our goal is to create a model that, given an unknown article headline, can classify it into one of these 4 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Our Data Set\n",
    "Our dataset consists of only two columns, *text* and *label*, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters) Re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Money Funds Fell in Latest Week (AP) AP - Asse...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fed minutes show dissent over inflation (USATO...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Safety Net (Forbes.com) Forbes.com - After ear...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black  NEW Y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
       "4  Oil prices soar to all-time record, posing new...      2\n",
       "5  Stocks End Up, But Near Year Lows (Reuters) Re...      2\n",
       "6  Money Funds Fell in Latest Week (AP) AP - Asse...      2\n",
       "7  Fed minutes show dissent over inflation (USATO...      2\n",
       "8  Safety Net (Forbes.com) Forbes.com - After ear...      2\n",
       "9  Wall St. Bears Claw Back Into the Black  NEW Y...      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('training_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text is, as the named suggests, just the headline of the news article, and label has it's classification according to the table mentioned before. As it is obvious, we need to process our text into tokens in order to use it in any prediction models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and Tokenizing\n",
    "We start by pre-processing our data, as described bellow, and also tokenizing it. Here we create the function **process_data()**, wich receives a dataset, as well as a number to indicate which iteration of the processing we are doing. Later in the notebook it will become clear that more processing is needed, but we didn't want to tamper with the initial results, so we created this way of adding new parts to the function, without making use of them.\n",
    "\n",
    "### Cleaning\n",
    "We start by using a regex to remove any HTML elements, to clean the text data.\n",
    "\n",
    "### Lowercase\n",
    "We then lowercase every word to ensure uniformity and prevent the model from treating words differently based on their capitalization.\n",
    "\n",
    "### Special Characters / Punctuation\n",
    "For this particular problem, special characters and punctuation marks don't contribute much to the meaning of the text and can be removed (opinion could be different if this was a sentiment analysis instead of a topic classification problem)\n",
    "\n",
    "### Tokenization\n",
    "We then split the text into individual words/tokens, as it helps capture semantic more effectively.\n",
    "\n",
    "### Stopwords\n",
    "Stopwords are common words that occur frequently in language, but, in a topic classification problem, carry virtually no useful information. Removing them reduces the noise in the data.\n",
    "\n",
    "### Stemming\n",
    "We reduce words to their base or root form, as it reduces the size of vocabulary and the dimensionality of the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def tokenize_numbers(text):\n",
    "    year_pattern = r'\\b\\d{4}\\b'\n",
    "    percentage_pattern = r'\\b\\d+(?:\\.\\d+)?%'\n",
    "    time_pattern = r'\\b\\d+\\s*(?:hours?|mins?|minutes?|secs?|seconds?|days?|weeks?|months?|years?|decades?)\\b'\n",
    "    number_pattern = r'\\b\\d+\\b'\n",
    "    date_pattern = r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b'  # Matches dates in mm/dd/yyyy and dd/mm/yyyy formats\n",
    "\n",
    "    # Tokenize numbers based on patterns\n",
    "    text = re.sub(percentage_pattern, 'percentagetoken', text)\n",
    "    text = re.sub(date_pattern, 'datetoken', text)\n",
    "    text = re.sub(year_pattern, 'yeartoken', text)\n",
    "    text = re.sub(time_pattern, 'timetoken', text)\n",
    "    text = re.sub(number_pattern, 'numbertoken', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def process_data(data, iteration):\n",
    "    if(iteration >= 2):\n",
    "        data['text'] = data['text'].apply(tokenize_numbers)\n",
    "\n",
    "    # Cleaning\n",
    "    data['text'] = data['text'].str.replace(r'#\\d+;', '', regex=True)\n",
    "\n",
    "    # Lowercase\n",
    "    data['text'] = data['text'].str.lower()\n",
    "\n",
    "    # Special Characters / Punctuation\n",
    "    data['text'] = data['text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "    # Tokenization\n",
    "    data['tokens'] = data['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "    # Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    if(type >= 2):\n",
    "        stop_words.update(['AP', 'Reuters', 'space.com', 'techweb', 'MacCentral', 'PC World', 'USATODAY.COM', 'CNN'])\n",
    "    data['tokens'] = data['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "    data['tokens'] = data['tokens'].apply(stem_tokens)\n",
    "    \n",
    "    print(data['tokens'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Now taht we can process our data, we can work on training some models. Here we create the function **train_data** to train a few models and compare which yield the best results when classifying the headline topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycaret.classification import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "def train_data(training_data, test_data):\n",
    "    X_train = training_data['text']\n",
    "    y_train = training_data['label']\n",
    "    X_val = test_data['text']\n",
    "    y_val = test_data['label']\n",
    "    \n",
    "    vectorizer = CountVectorizer(analyzer='word', max_features=5000, lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    X_val = vectorizer.transform(X_val)  # Transform validation data\n",
    "    \n",
    "    model_nb = MultinomialNB()\n",
    "    model_dt = DecisionTreeClassifier(random_state=123)\n",
    "    model_rf = RandomForestClassifier(random_state=123)\n",
    "    model_lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "        \n",
    "    print('----------------------------------------------------------------')\n",
    "    model_nb = model_nb.fit(X=X_train, y=y_train)\n",
    "    y_pred_nb = model_nb.predict(X_val)\n",
    "    print(\"Naive Bayes Accuracy:\", accuracy_score(y_val, y_pred_nb))\n",
    "    print(\"Naive Bayes Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_nb))\n",
    "    print(\"Naive Bayes Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_nb))\n",
    "    print()\n",
    "    '''\n",
    "    print('----------------------------------------------------------------')\n",
    "    model_dt = model_dt.fit(X=X_train, y=y_train)\n",
    "    y_pred_dt = model_dt.predict(X_val)\n",
    "    print(\"Decision Tree Accuracy:\", accuracy_score(y_val, y_pred_dt))\n",
    "    print(\"Decision Tree Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_dt))\n",
    "    print(\"Decision Tree Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_dt))\n",
    "    print()\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    model_rf = model_rf.fit(X=X_train, y=y_train)\n",
    "    y_pred_rf = model_rf.predict(X_val)\n",
    "    print(\"Random Forest Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
    "    print(\"Random Forest Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_rf))\n",
    "    print(\"Random Forest Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_rf))\n",
    "    print()\n",
    "    '''\n",
    "    print('----------------------------------------------------------------')\n",
    "    model_lr = model_lr.fit(X=X_train, y=y_train)\n",
    "    y_pred_lr = model_lr.predict(X_val)\n",
    "    print(\"Logistic Regression Accuracy:\", accuracy_score(y_val, y_pred_lr))\n",
    "    print(\"Logistic Regression Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_lr))\n",
    "    print(\"Logistic Regression Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_lr))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('training_data.csv')\n",
    "#training_data = pd.read_csv('training_data_xs.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "training_data = process_data(training_data, 2)\n",
    "test_data = process_data(test_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data(training_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
