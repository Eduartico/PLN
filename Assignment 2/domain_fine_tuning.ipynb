{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Topic Classification\n",
    "\n",
    "The project involves a large dataset of news articles collected over several years. These articles cover a wide range of topics such as world events, sports, business, and science/technology. Each article headline is labeled with a number from 0 to 3, indicating its category, as described below. \n",
    "\n",
    "| Value | Topic        |\n",
    "|:------|:-------------|\n",
    "| 0     | World        |\n",
    "| 1     | Sports       |\n",
    "| 2     | Business     |\n",
    "| 3     | Sci/Tech     |\n",
    "\n",
    "\n",
    "Our goal is to create a model that, given an unknown article headline, can classify it into one of these 4 topics.\n",
    "\n",
    "This specific notebook focuses on fine tuning a stabilished Domain Adapted model of our own as a way to solve the problem in hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data Set\n",
    "Our dataset consists of only two columns, *text* and *label*, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters) Re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Money Funds Fell in Latest Week (AP) AP - Asse...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fed minutes show dissent over inflation (USATO...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Safety Net (Forbes.com) Forbes.com - After ear...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black  NEW Y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
       "4  Oil prices soar to all-time record, posing new...      2\n",
       "5  Stocks End Up, But Near Year Lows (Reuters) Re...      2\n",
       "6  Money Funds Fell in Latest Week (AP) AP - Asse...      2\n",
       "7  Fed minutes show dissent over inflation (USATO...      2\n",
       "8  Safety Net (Forbes.com) Forbes.com - After ear...      2\n",
       "9  Wall St. Bears Claw Back Into the Black  NEW Y...      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('training_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the train functions\n",
    "Runing the model at first to have a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Transformer Model (./fine-tuned-distilbert) Accuracy: 0.7\n",
      "Transformer Model (./fine-tuned-distilbert) Confusion Matrix:\n",
      "[[3 0 2 0]\n",
      " [0 4 1 0]\n",
      " [0 0 5 0]\n",
      " [1 0 2 2]]\n",
      "Transformer Model (./fine-tuned-distilbert) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.50      1.00      0.67         5\n",
      "           3       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.81      0.70      0.70        20\n",
      "weighted avg       0.81      0.70      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "def train_data(training_data, test_data):\n",
    "    X_val = test_data['text']\n",
    "    y_val = test_data['label']\n",
    "\n",
    "    model_name = \"./fine-tuned-distilbert\"\n",
    "\n",
    "    tokenizer, model = load_model_and_tokenizer(model_name)\n",
    "    transformer_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    label_mapping = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3}\n",
    "\n",
    "    transformer_predictions = transformer_pipeline(X_val.tolist())\n",
    "    y_pred_transformer = [label_mapping[pred['label']] for pred in transformer_predictions]\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print(f\"Transformer Model ({model_name}) Accuracy:\", accuracy_score(y_val, y_pred_transformer))\n",
    "    print(f\"Transformer Model ({model_name}) Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_transformer))\n",
    "    print(f\"Transformer Model ({model_name}) Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_transformer))\n",
    "\n",
    "training_data = pd.read_csv('training_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "\n",
    "train_data(training_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model\n",
    "\n",
    "Now onto the fine-tuning: this was taken directly from the fine tuning notebook we went though. We ran this with the whole data-set with 120000 lines of data, which took around 6 hours on a laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1abd4fa0a7478290ab18d23f988610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3a1fb61a954098ba676ca561f9d75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd2b0c88bd2486683f6f256831930d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75a3664909b463a9ded0ae4203d55e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8011118173599243, 'eval_runtime': 2.7144, 'eval_samples_per_second': 7.368, 'eval_steps_per_second': 1.105, 'epoch': 1.0}\n",
      "{'loss': 0.2949, 'grad_norm': 0.11164164543151855, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e022d96b274dffaf075dee566e4206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5572220683097839, 'eval_runtime': 2.8254, 'eval_samples_per_second': 7.079, 'eval_steps_per_second': 1.062, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd89ac59d954b22817b5f8b487bb960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5526213645935059, 'eval_runtime': 2.6477, 'eval_samples_per_second': 7.554, 'eval_steps_per_second': 1.133, 'epoch': 3.0}\n",
      "{'train_runtime': 8625.2005, 'train_samples_per_second': 0.696, 'train_steps_per_second': 0.087, 'train_loss': 0.24927465311686198, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-fine-tuned-distilbert\\\\tokenizer_config.json',\n",
       " './fine-tuned-fine-tuned-distilbert\\\\special_tokens_map.json',\n",
       " './fine-tuned-fine-tuned-distilbert\\\\vocab.txt',\n",
       " './fine-tuned-fine-tuned-distilbert\\\\added_tokens.json',\n",
       " './fine-tuned-fine-tuned-distilbert\\\\tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "train_df = pd.read_csv('training_data.csv')\n",
    "train_df_subset = train_df.sample(n=2000, random_state=42)\n",
    "\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df_subset)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "model_name = \"./fine-tuned-distilbert\"\n",
    "\n",
    "tokenizer, model = load_model_and_tokenizer(model_name)\n",
    "transformer_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    max_length = min(512, max(len(text) for text in examples[\"text\"]))\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./fine-tuned-fine-tuned-distilbert\")\n",
    "tokenizer.save_pretrained(\"./fine-tuned-fine-tuned-distilbert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing our Results\n",
    "\n",
    "Here we run again the model, after fine-tuning, and have better results: 87% vs 81% precision, and 85% vs 70% on recall and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.71      1.00      0.83         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.87      0.85      0.85        20\n",
      "weighted avg       0.87      0.85      0.85        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine-tuned-fine-tuned-distilbert\")\n",
    "\n",
    "# Define a function to get predictions from the model\n",
    "def get_predictions(model, tokenizer, dataset):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    for batch in torch.utils.data.DataLoader(dataset, batch_size=8):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        predictions.extend(torch.argmax(outputs.logits, axis=1).tolist())\n",
    "        labels.extend(batch[\"labels\"].tolist())\n",
    "\n",
    "    return predictions, labels\n",
    "\n",
    "# Get predictions on the test dataset\n",
    "test_predictions, test_labels = get_predictions(model, tokenizer, tokenized_datasets[\"test\"])\n",
    "\n",
    "# Print evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
