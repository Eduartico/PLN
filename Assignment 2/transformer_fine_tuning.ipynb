{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Topic Classification\n",
    "\n",
    "The project involves a large dataset of news articles collected over several years. These articles cover a wide range of topics such as world events, sports, business, and science/technology. Each article headline is labeled with a number from 0 to 3, indicating its category, as described below. \n",
    "\n",
    "| Value | Topic        |\n",
    "|:------|:-------------|\n",
    "| 0     | World        |\n",
    "| 1     | Sports       |\n",
    "| 2     | Business     |\n",
    "| 3     | Sci/Tech     |\n",
    "\n",
    "\n",
    "Our goal is to create a model that, given an unknown article headline, can classify it into one of these 4 topics.\n",
    "\n",
    "This specific notebook focuses on fine tuning a tranformer as a way to solve the problem in hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data Set\n",
    "Our dataset consists of only two columns, *text* and *label*, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters) Re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Money Funds Fell in Latest Week (AP) AP - Asse...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fed minutes show dissent over inflation (USATO...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Safety Net (Forbes.com) Forbes.com - After ear...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black  NEW Y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
       "4  Oil prices soar to all-time record, posing new...      2\n",
       "5  Stocks End Up, But Near Year Lows (Reuters) Re...      2\n",
       "6  Money Funds Fell in Latest Week (AP) AP - Asse...      2\n",
       "7  Fed minutes show dissent over inflation (USATO...      2\n",
       "8  Safety Net (Forbes.com) Forbes.com - After ear...      2\n",
       "9  Wall St. Bears Claw Back Into the Black  NEW Y...      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('training_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    \"\"\"\n",
    "    Load the appropriate model and tokenizer based on the model name.\n",
    "    \"\"\"\n",
    "    if model_name == \"lucasresck/bert-base-cased-ag-news\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    elif model_name == \"fabriceyhc/bert-base-uncased-ag_news\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    else:  # Default to AutoModelForSequenceClassification for other models\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "def train_data(training_data, test_data):\n",
    "    X_train = training_data['text']\n",
    "    y_train = training_data['label']\n",
    "    X_val = test_data['text']\n",
    "    y_val = test_data['label']\n",
    "\n",
    "    transformer_models = [\n",
    "        \"textattack/roberta-base-ag-news\",\n",
    "        \"fabriceyhc/bert-base-uncased-ag_news\",\n",
    "        \"lucasresck/bert-base-cased-ag-news\",\n",
    "    ]\n",
    "\n",
    "    for model_name in transformer_models:\n",
    "        tokenizer, model = load_model_and_tokenizer(model_name)\n",
    "        transformer_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "        \n",
    "        transformer_predictions = transformer_pipeline(X_val.tolist())\n",
    "        y_pred_transformer = [int(pred['label'].split('_')[-1]) for pred in transformer_predictions]\n",
    "        \n",
    "        print('----------------------------------------------------------------')\n",
    "        print(f\"Transformer Model ({model_name}) Accuracy:\", accuracy_score(y_val, y_pred_transformer))\n",
    "        print(f\"Transformer Model ({model_name}) Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_val, y_pred_transformer))\n",
    "        print(f\"Transformer Model ({model_name}) Classification Report:\")\n",
    "        print(classification_report(y_val, y_pred_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-ag-news were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Transformer Model (textattack/roberta-base-ag-news) Accuracy: 0.6\n",
      "Transformer Model (textattack/roberta-base-ag-news) Confusion Matrix:\n",
      "[[4 0 1 0]\n",
      " [2 1 1 1]\n",
      " [0 0 4 1]\n",
      " [2 0 0 3]]\n",
      "Transformer Model (textattack/roberta-base-ag-news) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.80      0.62         5\n",
      "           1       1.00      0.20      0.33         5\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.69      0.60      0.57        20\n",
      "weighted avg       0.69      0.60      0.57        20\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Transformer Model (fabriceyhc/bert-base-uncased-ag_news) Accuracy: 0.7\n",
      "Transformer Model (fabriceyhc/bert-base-uncased-ag_news) Confusion Matrix:\n",
      "[[4 0 1 0]\n",
      " [2 2 0 1]\n",
      " [0 0 4 1]\n",
      " [1 0 0 4]]\n",
      "Transformer Model (fabriceyhc/bert-base-uncased-ag_news) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.80      0.80      0.80         5\n",
      "           3       0.67      0.80      0.73         5\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.76      0.70      0.69        20\n",
      "weighted avg       0.76      0.70      0.69        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Transformer Model (lucasresck/bert-base-cased-ag-news) Accuracy: 0.7\n",
      "Transformer Model (lucasresck/bert-base-cased-ag-news) Confusion Matrix:\n",
      "[[3 0 1 1]\n",
      " [3 2 0 0]\n",
      " [0 0 5 0]\n",
      " [1 0 0 4]]\n",
      "Transformer Model (lucasresck/bert-base-cased-ag-news) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.60      0.50         5\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.77      0.70      0.70        20\n",
      "weighted avg       0.77      0.70      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('training_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "\n",
    "train_data(training_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
